### 7.16
#### 项目背景和项目意义
背景：
为了高效利用现有业务产生的业务数据与平台采集的用户行为数据，帮助运营人员更精准的制定营销策略，进行精细化运营，以提升产品营销转化率、增加用户黏度，提高盈利水平。
意义：
1. 数据的可视化直观的展现了公司的运营状况，使运营人员得以准确的制定营销策略；
2. 通过对用户行为的分析，对用户进行精准推送；
3. 改善公司的运营流程。
#### 项目基本架构
我们项目的架构主要可以分数据采集、数据仓库、数据服务三块：
1. 数据采集：前后端埋点获取用户行为数据存储在日志服务器，业务系统数据库mysql存储业务数据，二者分别通过flume、sqoop传入到数据仓库的数据接入层。
2. 数据仓库主体，我们的数仓分为三层：
    - ODS层（原始数据层）:存放原始数据，直接加载原始日志、数据，保持数据原貌不做处理；
    - DW层（数据仓库层），由DWD、DWS组成：
    - DWD层（明细数据层）：对ODS层的数据进行清洗、预处理，采用一些维度退化手法，将维度退化至事实表中，减少事实表和维表的关联。
    - DWS层（服务数据层）：以DWD层的数据为基础，进行轻度汇总，整合汇总成分析某一个主题域的服务数据，一般是宽表。
    -  ADS层（数据应用层）：根据需求，以DW层的数据为基础，进行报表开发。
3. 数据服务：通过数据查询接口、引擎拉取ADS层的数据，进行分析、可视化，支撑OLAP分析平台。

#### 用到的技术栈
- 数据采集系统: Flume , Sqoop
- 数据存储: Mysql , HDFS ,Hbase
- 数据计算: Hive ,Spark
- 资源调度系统: Yarn
- 快速查询: Presto    快速查询
- 数据看台: SuperSet  展示数据
- 任务调度:  DolphinScheduler    azkaban 
- 元数据管理: Atlas 

#### flume采集本地数据到HDFS，生成一个大文件
```conf
# 默认数据大量的小文件  , 改变输出策略   ,128M滚动一个输出文件
# 默认是30秒滚动生成一个文件  0 禁用时间滚动生成文件
a1.sinks.k1.hdfs.rollInterval = 0
# 默认是1K滚动生成一个文件   128M生成一个文件
a1.sinks.k1.hdfs.rollSize = 134217728
# 默认是10条Event生成一个文件  0 代表禁用以事件个数生成文件的策略
a1.sinks.k1.hdfs.rollCount = 0
```
---

### 7.17
#### 你在项目里主要的核心工作有哪些
主要的工作内容有：1.对接并梳理业务需求,开发数据仓库模型,设计相关主题的事实表和维度表等；2.对原始数据进行转化处理；3.完成业务需求指标。
次要的工作内容有：任务调度脚本的编写、数据质量的监测、元数据的管理。


#### flume的核心组件和功能
Flume中最核心的角色是agent，每一个Agent都是一个独立的守护线程（JVM），负责从数据源接收数据发送到目的地，一个个agent连接起来形成flume采集系统。

每一个agent相当于一条数据(被封装成Event对象)传递员，内部有3个核心组件： 
- Source：数据源组件，用于跟数据源对接，获取数据； 
- Channel：传输通道组件（缓冲区），用于协调和解耦source & sink；
- Sink：下沉组件，用于往下一级agent传递数据或者向最终存储系统传递数据。

#### 拦截器的作用与自定义拦截器的开发步骤
Flume在运行时，可以通过拦截器来实现对Event进行修改或丢弃。

自定义拦截器的开发步骤：
1. 定义一个类，实现Interceptor接口；
2. 实现四个方法：initialize、Event intercept、List intercept、close，方法的作用分别是初始化拦截器、拦截每条事件处理、处理所有事件、拦截器结束；
3. 创建一个静态内部类拦截器构建器，因为自定义拦截器的类无法直接new，需要通过flume配置文件调用静态内部类，来间接地调用自定义的拦截器对象。

#### 你们工作时使用的是什么source、channel,为什么使用他们
source我们用的是Taildir Source，因为它比较可靠的，即使发生文件轮换不会丢失数据。它有一个专门记录每个文件的最后读取位置的JSON格式文件。如果Flume停了，可以从文件的标记位置重新开始读取。另外它读取的规则是先来先走，按照修改时间的顺序来读取。（缺点不支持读取二进制文件。只能逐行读取文本文件）
channel我们用的是File Channel，因为如果使用Memory Channel，虽然说数据吞吐快，但在发生故障时会有数据漏采，而File Channel能通过设置检查点文件,对数据进行恢复。

---
### 7.19
#### flume的事务了解吗? 说一下flume的事务：事务分类,事务的流程,事务效果 
flume的事务有put事务和take事务，能保证数据至少被执行一次。
put事务：
source采集一批数据封装为event后，会开启事务。put事务首先执行doPut方法，将这批event写入到临时缓冲区putList，然后执行doCommit方法检查channel的容量是否足够合并，channel的容量足够则缓冲区的event与channel合并，提交event成功；若channel容量不足，则将对event回滚，将putList中的数据清除掉，告知source数据未采集，重新采集这批数据，开启新事务。
take事务：
调用doTake方法将channel中的event剪切到临时缓冲区takeList，同时也拷贝一份event发送到写往hdfs的IO流中，如果event全部发送成功，调用doCommit方法清除takeList，如果发生过程中出现异常，调用doRollback方法回滚，将takeList中的event全部归还给channel，不过这个操作可能会产生数据重复。

flume的事务仅能保证两个传输阶段的数据不丢，如果channel选用memory channel，一旦channel发生异常，数据仍然可能发生数据丢失，如果采用file channel，虽然数据传输到channel时会落盘，但结合事务能保证整体上数据不丢失，不过也有可能产生数据重复的问题。

#### 什么是flume的failover机制
Flume的failover机制是在上游配置多个sink , 组成一个失败会自动切换的sink组，同一个sink组中的sink根据配置的sink优先级来进行日志采集﹒优先级别高的sink作为主sink进行处理数据，优先级低的sink作为备用sink。当主sink出现故障时,channel负责切换到备用sink上.在数据采集的过程中会不断地尝试主sink是否恢复。

#### flume的内部的主要组件
- Source：数据源组件，用于跟数据源对接，以获取数据； 
- Sink：下沉组件，用于往下一级agent传递数据或者向最终存储系统传递数据；
- Channel：传输通道组件（缓冲区），用于协调和解耦source & sink；
- interceptor拦截器：可以通过拦截器来实现对Event进行修改或甚至丢弃，为用户提供数据处理的逻辑；
- channel selector选择器：一个source可以对接多个channel，channel selector决定event在channel之间的传递策略。选择器有两种实现，默认为replicating（复制），另一种是multiplexing（多路复用），使用多路复用可实现负载均衡、并行输出。

#### 说说flume的优化
1. 事务：保证数据完整性；
2. 级联：保证生产安全；
3. failoverHA：热备模式，提高容错，应对积压问题；
4. 上下游之间的avro传递使用压缩、通过多sink实现多线程；
5. 使用选择器：负载均衡、并行输出，提升数据写HDFS的效率。

---
### 7.20
#### 日志采集系统的优化
1. 使用Taildir Source+File Channel保证数据的完整性；
2. 配置成failover sink组，实现HA模式，防止产生数据积压；
3. 上下游之间的avro传递使用压缩 compression-Type，提高传输效率；
4. 下游agent使用选择器，实现多sink并行输出；
5. hdfs上的数据按照gzip格式存储。
#### 日志采集系统数据积压问题总结
原因：下游出现故障或写出数据跟不上读取速度，导致channel中的数据积压过多。

首先我们的配置采用的是富裕配置，在采集上游配置了failoverHA，避免了上游的积压，
然后在采集下游我们配置了多channel负载均衡，多个sink并行输出，也避免了下游的积压。

#### 数据量问题 业务特征 规模 用户规模  计算 (时长, 事件频次, 日志数据大小 ,用户数据)
5000w用户  日活15%  750w
每天平均访问20分钟，10s产生一条日志，0.5k
每天总数据：750w*20*6*0.5=450000000kb=440000M=430G
平均5M/s,考虑业务高峰期是平时的15倍，高峰期时也就是75M/s
第一层3台flume服务器，每台服务器最大数据25M/s
第二层1台flume服务器，汇聚上层3台服务器数据最大75M/s
我们的服务器采用的是富裕配置，avro sources数据传输速度是150M/s，所以这个数据量是没多大压力的。
此外还配置了failoverHA模式提高容错防止数据积压，并且下游agent还配置了选择器进行多sink并行输出（单个35M/s）。

#### 数据延迟 ,数据丢失 , 数据重复
**数据延迟：**
原因：
1. 数据传输有延迟；
2. 数据是批次处理的，不满足一批不会执行；
3. 网络延迟。

解决：
1. 数据划分以拦截器获取的日志时间为准；
2. 将统计计算任务向后推1h，计算任务在第二天1：00开始；
3. 在3：00的时候检查统计时与此时的数据条数的变化，根据延迟阈值判断是否重新计算。

**数据丢失：**
我们的flume采集是不会丢数据的  
  - 我们第一级采用了taildir source，它实现了flume的事务机制，也记录了数据读取偏移量；
  - 两级agent都采用了file channel，数据落地磁盘 ,并且有checkpoint（内存队列的快照）机制；
  - sink有时事务保证,下游落地后才会conmmit事务

**数据重复：**
我们的flume采集确实会出现数据重复问题，比如sink向channel取数据的事务执行到一半发生了错误，那么这整批event将会再次执行。
数据重复判断：
我们有数据管理平台，可以汇总各个服务器产生以及hdfs收集的日志条数，两者进行对比就可以判断是否有数据重复。 
数据重复应对：在报表计算任务之前判断是否有重复，若有则先执行一个去重计算任务。
行数统计：
本地文本 cat file | wc -l
hdfs hdfs dfs -text filepath | wc -l


---
### 7.23
#### 为什么开发数据服务总线这个服务
这个服务在数据采集阶段主要有两个作用，一是日志上报服务，日志服务器与hdfs集群会通过脚本统计日志产生与采集的条数，然后通过POST请求将日志条数上报到服务端，服务端会调用对应的方法将日志统计数据存储到MySQL的表中。另外一个作用就是日志条数查询，也就是通过请求服务端的API，服务端调用方法查询MySQL表，返回日志条数。通过对日志条数的对比，我们就可以知道数据是否有重复采集的问题。

#### 数据去重流程 
首先我们会通过脚本请求数据服务总线，获取每天各个日志服务器产生的日志总行数以及HDFS采集到的的日志总行数，对二者进行比较判断是否需要去重。
如果需要去重，我们可以通过Spark-SQL、Spark-Core或者Hive-SQL进行去重。
如果使用hive的话，我们会先创建一张按日期分区的外部表，将原始日志目录中的数据映射到分区表下，然后使用group by进行去重，将通过insert...select...将去重后的数据覆盖掉原来的数据或者输出到去重文件夹中。
#### 数据入库(表有结构)流程  解析压缩文件
在对日志数据进行去重以后，会对数据进行入库操作，将其载入ODS层。首先我们会创建一张分区的外部表，配置JsonSerde使其数据结构按json格式进行映射，然后再通过脚本将去重后的数据加载到指定表的指定分区下，对入库的结果会使用邮件通知。

#### 讲一下数据预处理
采集到的原始数据一般都会存在脏数据，为了提高数据的质量并方便后续对数据的操作，是需要对数据进行预处理的。
预处理分为四个步骤：
第一步是数据清洗，主要是对一些异常或者缺失的脏数据进行处理；
第二步是数据集成，将多个数据源合并到一个数据存储中；
第三步是数据变换，将数据转换成适当的形式，方便后续的处理；
第四步是数据规约，通过如聚集、删除冗余特征或聚类，在尽可能保持数据原貌的前提下，来降低数据规模，提高运行速度。