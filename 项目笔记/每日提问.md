### 7.16
#### 项目背景和项目意义
背景：
为了高效利用现有业务产生的业务数据与平台采集的用户行为数据，帮助运营人员更精准的制定营销策略，进行精细化运营，以提升产品营销转化率、增加用户黏度，提高盈利水平。
意义：
1. 数据的可视化直观的展现了公司的运营状况，使运营人员得以准确的制定营销策略；
2. 通过对用户行为的分析，对用户进行精准推送；
3. 改善公司的运营流程。
#### 项目基本架构
我们项目的架构主要分为三个层面：
1. 数据采集层：前后端埋点获取用户行为数据存储在日志服务器，业务系统数据库mysql存储业务数据，二者分别通过flume、sqoop传入到数据仓库的数据接入层。
2. 数据仓库主体，我们的数仓分为三层：
    - ODS层（原始数据层）:存放原始数据，直接加载原始日志、数据，保持数据原貌不做处理；
    - DW层（数据仓库层），由DWD、DWS组成：
    - DWD层（明细数据层）：对ODS层的数据进行清洗、预处理，采用一些维度退化手法，将维度退化至事实表中，减少事实表和维表的关联。
    - DWS层（服务数据层）：以DWD层的数据为基础，进行轻度汇总，整合汇总成分析某一个主题域的服务数据，一般是宽表。
    -  ADS层（数据应用层）：根据需求，以DW层的数据为基础，进行报表开发。
3. 数据服务层：通过数据查询接口、引擎拉取ADS层的数据，进行分析、可视化，支撑OLAP分析平台。

#### 用到的技术栈
- 数据采集系统: Flume , Sqoop
- 数据存储: Mysql , HDFS ,Hbase
- 数据计算: Hive ,Spark
- 资源调度系统: Yarn
- 快速查询: Presto    快速查询
- 数据看台: SuperSet  展示数据
- 任务调度:  DolphinScheduler    azkaban 
- 元数据管理: Atlas 

#### flume采集本地数据到HDFS，生成一个大文件
```conf
# 默认数据大量的小文件  , 改变输出策略   ,128M滚动一个输出文件
# 默认是30秒滚动生成一个文件  0 禁用时间滚动生成文件
a1.sinks.k1.hdfs.rollInterval = 0
# 默认是1K滚动生成一个文件   128M生成一个文件
a1.sinks.k1.hdfs.rollSize = 134217728
# 默认是10条Event生成一个文件  0 代表禁用以事件个数生成文件的策略
a1.sinks.k1.hdfs.rollCount = 0
```
---

### 7.17
#### 你在项目里主要的核心工作有哪些
主要的工作内容有：1.对接并梳理业务需求,开发数据仓库模型,设计相关主题的事实表和维度表等；2.对原始数据进行转化处理；3.完成业务需求指标。
次要的工作内容有：任务调度脚本的编写、数据质量的监测、元数据的管理。


#### flume的核心组件和功能
Flume中最核心的角色是agent，每一个Agent都是一个独立的守护线程（JVM），负责从数据源接收数据发送到目的地，一个个agent连接起来形成flume采集系统。

每一个agent相当于一条数据(被封装成Event对象)传递员，内部有3个核心组件： 
- Source：数据源组件，用于跟数据源对接，获取数据； 
- Channel：传输通道组件（缓冲区），用于协调和解耦source & sink；
- Sink：下沉组件，用于往下一级agent传递数据或者向最终存储系统传递数据。

#### 拦截器的作用与自定义拦截器的开发步骤
Flume在运行时，可以通过拦截器来实现对Event进行修改或丢弃。

自定义拦截器的开发步骤：
1. 定义一个类，实现Interceptor接口；
2. 实现四个方法：initialize、Event intercept、List intercept、close，方法的作用分别是初始化拦截器、拦截每条事件处理、处理所有事件、拦截器结束；
3. 创建一个静态内部类拦截器构建器，因为自定义拦截器的类无法直接new，需要通过flume配置文件调用静态内部类，来间接地调用自定义的拦截器对象。

#### 你们工作时使用的是什么source、channel,为什么使用他们
source我们用的是Taildir Source，因为它比较可靠的，即使发生文件轮换不会丢失数据。它有一个专门记录每个文件的最后读取位置的JSON格式文件。如果Flume停了，可以从文件的标记位置重新开始读取。另外它读取的规则是先来先走，按照修改时间的顺序来读取。（缺点不支持读取二进制文件。只能逐行读取文本文件）
channel我们用的是File Channel，因为如果使用Memory Channel，虽然说数据吞吐快，但在发生故障时会有数据漏采，而File Channel能通过设置检查点文件,对数据进行恢复。