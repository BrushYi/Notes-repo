- 数据预处理阶段需要对一些敏感数据进行数据脱敏，比如加密或去敏感词，这个操作也可以在数据采集阶段进行，但为了防止脱敏失败影响数据的采集，尽量不在采集阶段对数据进行过多的操作。
- 计算或分析依据的那个字段可以看作是维度。
- 了解数据仓库研发岗位的日常工作流程为:
1.和产品开需求评审会，了解需求(那种需求?)，进行开发排期;
2.模型设计，了解依赖关系与约束原则，与产品二次核对;
3.数据同步ETL开发，沟通其他部门(DBA)，导入数据;
4.SQL/数据处理代码开发，编写业务逻辑;
5.自测;
6.测试，测试人员检查逻辑，并核对结果准确性;
7.发布上线,加入日常监控报警。
- 建模:根据不同的统计业务需求﹒制定出比较合理的表结构和计算逻辑。
- 全量表-增量表-拉链表-流水表
  1. 全量表：每天的所有的最新状态的数据，
  2. 增量表：每天的新增数据，增量数据是上次导出之后的新数据。
  3. 拉链表：维护历史状态，以及最新状态数据的一种表，拉链表根据拉链粒度的不同，实际上相当于快照，只不过做了优化，去除了一部分不变的记录而已,通过拉链表可以很方便的还原出拉链时点的客户记录。
  4. 流水表： 对于表的每一个修改都会记录，可以用于反映实际记录的变更。 
- 实体表，事实表，维度表
  1. 实体表：实体表是一个实际对象的表，存放的数据是客观存在的事物数据，比如说各种商品。实时表只描述各个事物，并不存在具体的事实。
  2. 事实表：事实表是维度建模的核心，包含了与业务过程有关的维度引用及度量，围绕业务过程进行设计，其存储的数据是实际发生的，比如用户的行为。
  3. 维度表：维度表是维度建模的基础和灵魂，也就是维度建模时事实表关联的表。维度表围绕业务过程所处的环境进行设计，主要包含一个主键和各种维度字段。
- 粒度：每条数据的单位
- hive中拉链表是需要分区的，每个分区内的数据都是最开始到当天的全量数据，这样也就产生了冗余，对此可以只保存最近一周分区的拉链表数据。（因为hive的表中的数据无法进行修改，故只能通过分区将最新的全量数据保存）
- 主题域的划分是针对需求对明细数据进行操作，将结果或者中间表划分到相应主题域下。
- 轻度聚合和维度表设计都在建模的范畴里。
- 分析业务需求后，构建维表时进行维度表设计，而后根据事实表和维度表关联进行维度建模，开发报表。
- 中心事实表、维度表是有模糊边界的。比如雪花模型中，事实表A关联维度表B，维度表B关联维度表C，这时对于B、C两表，B表可以作为中心事实表。
- ER建模三范式
  1. 第一范式要求确保表中每列的原子性，即不可拆分；
  2. 第二范式要求实体的属性完全依赖于主关键字；
  3. 第二范式确保每个属性都直接依赖主键，而不是依赖于其它非主属性，即在2NF的基础之上消除传递依赖。
- 为什么用雪花模型，我们的业务模型遵循三范式，表连接比较多。